*** Begin Patch`n*** Update File: models/model_trainer.py`n@@`n     def evaluate_model(self, model_name: str, data_processor: DataProcessor) -> Dict:`n@@`n-        # Load model`n+        # If prior evaluation results are available, load and return (skip recompute)`n+        prior_results_path = os.path.join(model_path, "evaluation_results.json")`n+        if os.path.exists(prior_results_path):`n+            try:`n+                with open(prior_results_path, "r") as f:`n+                    cached = json.load(f)`n+                # Attach auxiliary metadata if available`n+                cached["model_name"] = model_name`n+                cached["model_type"] = metadata.get("model_type", cached.get("model_type", "pytorch"))`n+                print(f"Loaded cached evaluation results from {prior_results_path}")`n+                return cached`n+            except Exception as _:`n+                # Fall back to full evaluation if cache cannot be read`n+                pass`n+`n+        # Load model`n         print(f"Loading model from {model_path}...")`n*** End Patch